{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handmade-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "digits = load_digits()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "varied-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dir(digits))\n",
    "\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "direct-contemporary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "premier-topic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "saving-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "proprietary-polish",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "taken-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "x = digits.data\n",
    "y = digits.target\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "august-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indirect-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        35\n",
      "           1       0.76      0.89      0.82        35\n",
      "           2       0.81      0.83      0.82        36\n",
      "           3       0.97      0.78      0.87        37\n",
      "           4       0.76      0.78      0.77        32\n",
      "           5       0.90      0.83      0.86        46\n",
      "           6       0.87      0.87      0.87        30\n",
      "           7       0.86      0.86      0.86        42\n",
      "           8       0.92      0.87      0.89        38\n",
      "           9       0.74      1.00      0.85        29\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.86      0.86      0.85       360\n",
      "weighted avg       0.86      0.85      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(x_train, y_train)\n",
    "y_pred = tree_clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "played-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        35\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      0.97      0.99        37\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       0.98      0.96      0.97        46\n",
      "           6       1.00      0.97      0.98        30\n",
      "           7       0.98      0.98      0.98        42\n",
      "           8       0.95      0.97      0.96        38\n",
      "           9       0.93      0.97      0.95        29\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.98      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "y_pred = rf_clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dated-pepper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      0.95      0.97        37\n",
      "           4       1.00      1.00      1.00        32\n",
      "           5       0.96      0.98      0.97        46\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       1.00      0.98      0.99        42\n",
      "           8       0.95      0.95      0.95        38\n",
      "           9       0.90      0.93      0.92        29\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(x_train, y_train)\n",
    "y_pred = svc_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "angry-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.97      0.86      0.91        35\n",
      "           2       0.92      0.97      0.95        36\n",
      "           3       1.00      0.89      0.94        37\n",
      "           4       1.00      0.97      0.98        32\n",
      "           5       0.98      0.96      0.97        46\n",
      "           6       1.00      0.97      0.98        30\n",
      "           7       0.95      0.98      0.96        42\n",
      "           8       0.77      0.97      0.86        38\n",
      "           9       0.96      0.90      0.93        29\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.96      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(x_train, y_train)\n",
    "y_pred = sgd_clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "short-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.89      0.97      0.93        35\n",
      "           2       0.95      1.00      0.97        36\n",
      "           3       0.97      0.95      0.96        37\n",
      "           4       0.97      0.91      0.94        32\n",
      "           5       0.98      0.93      0.96        46\n",
      "           6       1.00      0.97      0.98        30\n",
      "           7       0.98      0.98      0.98        42\n",
      "           8       0.97      0.92      0.95        38\n",
      "           9       0.88      0.97      0.92        29\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_reg = LogisticRegression(max_iter = 10000)\n",
    "lg_reg.fit(x_train, y_train)\n",
    "y_pred = lg_reg.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-leeds",
   "metadata": {},
   "source": [
    "테스트데이터 예측 결과 해석\n",
    "===================\n",
    "\n",
    "모든 라벨의 예측 결과에 대해 정밀도와 재현율이 높게 측정된 랜덤포레스트모델과 서포트벡터머신 모델이 적절한 모델이라고 예상됩니다.두 모델 모두 모든 분류에 대해 0.9 이상의 퍼포먼스를 보여주고 있고 전체 정확도도 각각 0.97과 0.98로 높습니다.\n",
    "\n",
    "나머지 모델은 몇몇 분류에 있어 정밀도나 재현율이 낮게 나오는 경향이 있고, 정확도도 랜덤포레스트나 서포트벡터머신에 비해 낮습니다.     \n",
    "\n",
    "랜덤포레스트 기법과 서포트벡터머신 기법 모두 우수한 결과물을 보여줬으나 해당실습에서는 최종적으로 랜덤포레스트보다 서포트벡터머신이 좀 더 좋은 선택이 되리라 생각됩니다.\n",
    "\n",
    "랜덤포레스트는 모델에 들어갈 요인을 랜덤으로 선정하여 여러 모델을 생성한 후 앙상블하는 기법입니다. 그에 비해 서포트벡터머신은 모든 요인을 고려하여 학습한 후 경계를 만들어내어 분류하는 기법입니다. 향후에 더 양이 많고 불규칙적인 데이터에 대한 분석은 랜덤포레스트 기법이 더 맞으리라 생각되지만 해당 실습처럼 8x8의 작은 이미지의 상대적으로 규칙적인 데이터에서는 서포트벡터머신이 좀 더 논리적으로 적합한 기법이라 생각됩니다.\n",
    "\n",
    "로직스틱리그레션의 경우 충분히 좋은 성능을 보여주고 있으나 랜덤포레스트나 서포트벡터머신에 비해 약간 아쉬운 성능을 보여주고 있습니다. 정확한 이유는 알 수 없으나 라벨의 종류가 많아 모델의 복잡도에 영향을 미쳐서 생긴 문제가 아닌가 싶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-palace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
